{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"Hello!\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hello!\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"Hi!\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi!\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { ChatMessageHistory } from 'langchain/stores/message/in_memory'\n",
    "import { HumanMessage, AIMessage } from '@langchain/core/messages'\n",
    "\n",
    "const history = new ChatMessageHistory()\n",
    "\n",
    "await history.addMessage(new HumanMessage('Hello!'))\n",
    "await history.addMessage(new AIMessage('Hi!'))\n",
    "\n",
    "const messages = await history.getMessages()\n",
    "console.log(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import env config\n",
    "\n",
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts'\n",
    "\n",
    "import { ChatOpenAI } from '@langchain/openai'\n",
    "\n",
    "const chatModel = new ChatOpenAI()\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "        You are talkative and provides lots of specific details from its context. \n",
    "        If the you does not know the answer to a question, it truthfully says you do not know.`],\n",
    "    new MessagesPlaceholder('history_message')\n",
    "])\n",
    "\n",
    "const chain = prompt.pipe(chatModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Hello Bob! How can I assist you today?\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Hello Bob! How can I assist you today?\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 10, promptTokens: 72, totalTokens: 82 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatMessageHistory } from 'langchain/stores/message/in_memory'\n",
    "import { HumanMessage } from '@langchain/core/messages'\n",
    "\n",
    "const history = new ChatMessageHistory()\n",
    "await history.addMessage(new HumanMessage('Hello! My name is Bob.'));\n",
    "\n",
    "const res = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "\n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Your name is Bob.\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Your name is Bob.\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 5, promptTokens: 95, totalTokens: 100 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "await history.addMessage(res)\n",
    "await history.addMessage(new HumanMessage('What is my name?'))\n",
    "\n",
    "const res2 = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "\n",
    "console.log(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manully manage memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from '@langchain/openai'\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts'\n",
    "import { ChatMessageHistory } from 'langchain/stores/message/in_memory'\n",
    "import { RunnableWithMessageHistory } from '@langchain/core/runnables'\n",
    "\n",
    "\n",
    "const chatModel = new ChatOpenAI()\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "        You are talkative and provides lots of specific details from its context. \n",
    "        If the you does not know the answer to a question, it truthfully says you do not know.`],\n",
    "    new MessagesPlaceholder('history_message'),\n",
    "    ['human', '{input}']\n",
    "])\n",
    "\n",
    "const history = new ChatMessageHistory()\n",
    "const chain = prompt.pipe(chatModel)\n",
    "\n",
    "const chainWithHistory = new RunnableWithMessageHistory({\n",
    "    runnable: chain,\n",
    "    getMessageHistory: _sessionId => history,\n",
    "    inputMessageKey: 'input',\n",
    "    historyMessagesKey: 'history_message' // spelling issue 's' missing\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Hello, Bob! How can I assist you today?\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Hello, Bob! How can I assist you today?\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 11, promptTokens: 104, totalTokens: 115 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res1 = await chainWithHistory.invoke({\n",
    "    input: 'Hello! My name is Bob.',\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "\n",
    "console.log(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Your name is Bob.\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Your name is Bob.\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 5, promptTokens: 128, totalTokens: 133 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res2 = await chainWithHistory.invoke({\n",
    "    input: 'What is my name?',\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "\n",
    "console.log(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"hi, my name is Kai\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"hi, my name is Kai\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hello, Kai! It's nice to meet you. How can I assist you today?\"\u001b[39m,\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hello, Kai! It's nice to meet you. How can I assist you today?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m18\u001b[39m, promptTokens: \u001b[33m71\u001b[39m, totalTokens: \u001b[33m89\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hello! My name is Bob.\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hello! My name is Bob.\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hello, Bob! How can I assist you today?\"\u001b[39m,\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hello, Bob! How can I assist you today?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m11\u001b[39m, promptTokens: \u001b[33m104\u001b[39m, totalTokens: \u001b[33m115\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Your name is Bob.\"\u001b[39m,\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Your name is Bob.\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m5\u001b[39m, promptTokens: \u001b[33m128\u001b[39m, totalTokens: \u001b[33m133\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    }\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await history.getMessages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Chat history abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
