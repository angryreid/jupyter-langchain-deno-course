{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"Hello!\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hello!\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"Hi!\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi!\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { ChatMessageHistory } from 'langchain/stores/message/in_memory'\n",
    "import { HumanMessage, AIMessage } from '@langchain/core/messages'\n",
    "\n",
    "const history = new ChatMessageHistory()\n",
    "\n",
    "await history.addMessage(new HumanMessage('Hello!'))\n",
    "await history.addMessage(new AIMessage('Hi!'))\n",
    "\n",
    "const messages = await history.getMessages()\n",
    "console.log(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import env config\n",
    "\n",
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts'\n",
    "\n",
    "import { ChatOpenAI } from '@langchain/openai'\n",
    "\n",
    "const chatModel = new ChatOpenAI()\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "        You are talkative and provides lots of specific details from its context. \n",
    "        If the you does not know the answer to a question, it truthfully says you do not know.`],\n",
    "    new MessagesPlaceholder('history_message')\n",
    "])\n",
    "\n",
    "const chain = prompt.pipe(chatModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Hello Bob! How can I assist you today?\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Hello Bob! How can I assist you today?\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 10, promptTokens: 72, totalTokens: 82 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatMessageHistory } from 'langchain/stores/message/in_memory'\n",
    "import { HumanMessage } from '@langchain/core/messages'\n",
    "\n",
    "const history = new ChatMessageHistory()\n",
    "await history.addMessage(new HumanMessage('Hello! My name is Bob.'));\n",
    "\n",
    "const res = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "\n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Your name is Bob.\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Your name is Bob.\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 5, promptTokens: 95, totalTokens: 100 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "await history.addMessage(res)\n",
    "await history.addMessage(new HumanMessage('What is my name?'))\n",
    "\n",
    "const res2 = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "\n",
    "console.log(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manully manage memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from '@langchain/openai'\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts'\n",
    "import { ChatMessageHistory } from 'langchain/stores/message/in_memory'\n",
    "import { RunnableWithMessageHistory } from '@langchain/core/runnables'\n",
    "\n",
    "\n",
    "const chatModel = new ChatOpenAI()\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "        You are talkative and provides lots of specific details from its context. \n",
    "        If the you does not know the answer to a question, it truthfully says you do not know.`],\n",
    "    new MessagesPlaceholder('history_message'),\n",
    "    ['human', '{input}']\n",
    "])\n",
    "\n",
    "const history = new ChatMessageHistory()\n",
    "const chain = prompt.pipe(chatModel)\n",
    "\n",
    "const chainWithHistory = new RunnableWithMessageHistory({\n",
    "    runnable: chain,\n",
    "    getMessageHistory: _sessionId => history,\n",
    "    inputMessageKey: 'input',\n",
    "    historyMessagesKey: 'history_message' // spelling issue 's' missing\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Hello, Bob! How can I assist you today?\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Hello, Bob! How can I assist you today?\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 11, promptTokens: 104, totalTokens: 115 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res1 = await chainWithHistory.invoke({\n",
    "    input: 'Hello! My name is Bob.',\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "\n",
    "console.log(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: \"Your name is Bob.\",\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "  content: \"Your name is Bob.\",\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 5, promptTokens: 128, totalTokens: 133 },\n",
      "    finish_reason: \"stop\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res2 = await chainWithHistory.invoke({\n",
    "    input: 'What is my name?',\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "\n",
    "console.log(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"hi, my name is Kai\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"hi, my name is Kai\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hello, Kai! It's nice to meet you. How can I assist you today?\"\u001b[39m,\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hello, Kai! It's nice to meet you. How can I assist you today?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m18\u001b[39m, promptTokens: \u001b[33m71\u001b[39m, totalTokens: \u001b[33m89\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hello! My name is Bob.\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hello! My name is Bob.\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Hello, Bob! How can I assist you today?\"\u001b[39m,\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Hello, Bob! How can I assist you today?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m11\u001b[39m, promptTokens: \u001b[33m104\u001b[39m, totalTokens: \u001b[33m115\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    }\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"What is my name?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {},\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Your name is Bob.\"\u001b[39m,\n",
       "      additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Your name is Bob.\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {\n",
       "      tokenUsage: { completionTokens: \u001b[33m5\u001b[39m, promptTokens: \u001b[33m128\u001b[39m, totalTokens: \u001b[33m133\u001b[39m },\n",
       "      finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "    }\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await history.getMessages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Chat history abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";\n",
    "import { RunnableSequence } from \"@langchain/core/runnables\";\n",
    "import { RunnablePassthrough } from \"@langchain/core/runnables\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { getBufferString } from \"@langchain/core/messages\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "const summaryModel = new ChatOpenAI();\n",
    "const summaryPrompt = ChatPromptTemplate.fromTemplate(`\n",
    "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "New lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:\n",
    "`); \n",
    "\n",
    "const summaryChain = RunnableSequence.from([\n",
    "    summaryPrompt,\n",
    "    summaryModel,\n",
    "    new StringOutputParser(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "const newSummary = await summaryChain.invoke({\n",
    "    summary: '',\n",
    "    new_lines: \"I'm 18\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"The person identifies as an 18-year-old male.\"\u001b[39m"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await summaryChain.invoke({\n",
    "    summary: newSummary,\n",
    "    new_lines: \"I'm male\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "const chatModel = new ChatOpenAI();\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "\n",
    "    Here is the chat history summary:\n",
    "    {history_summary}\n",
    "    `],\n",
    "    [\"human\",\"{input}\"]\n",
    "]);\n",
    "let summary = \"\"\n",
    "const history = new ChatMessageHistory();\n",
    "\n",
    "const chatChain = RunnableSequence.from([\n",
    "    {\n",
    "        input: new RunnablePassthrough({\n",
    "             func: (input) => history.addUserMessage(input)\n",
    "        })\n",
    "    },\n",
    "    RunnablePassthrough.assign({\n",
    "        history_summary: () => summary\n",
    "    }),\n",
    "    chatPrompt,\n",
    "    chatModel,\n",
    "    new StringOutputParser(),\n",
    "    new RunnablePassthrough({\n",
    "        func: async (input) => {\n",
    "            history.addAIChatMessage(input)\n",
    "            const messages = await history.getMessages()\n",
    "            const new_lines = getBufferString(messages)\n",
    "            const newSummary = await summaryChain.invoke({\n",
    "                summary,\n",
    "                new_lines\n",
    "            })\n",
    "            console.log(summary, input, messages, new_lines, newSummary)\n",
    "            history.clear()\n",
    "            summary = newSummary      \n",
    "        }\n",
    "    })\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Hello Bob! How can I assist you today?\"\u001b[39m"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatChain.invoke(\"Hello! My name is Bob.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob introduces himself and the AI responds by greeting him and offering assistance.\n"
     ]
    }
   ],
   "source": [
    "console.log(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"I'm sorry to hear that you're tired. Is there anything I can do to help?\"\u001b[39m"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatChain.invoke(\"I'm tired now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob mentions that he is tired, to which the AI expresses sympathy and offers assistance.\n"
     ]
    }
   ],
   "source": [
    "console.log(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob expresses his desire for a world without wars, to which the AI acknowledges the noble goal and highlights the importance of individuals promoting peace in their own lives and communities. The AI suggests spreading empathy, understanding, and actively working towards peacefully resolving conflicts as ways to contribute to a more peaceful world. I understand your desire for a world without wars. It's a noble goal that many people share. While achieving a completely war-free world may be challenging, it is important for individuals to promote peace in their own lives and communities. Spreading empathy and understanding, and actively working towards peacefully resolving conflicts can all contribute to a more peaceful world. It starts with small actions, and by collectively working towards peace, we can make a difference. [\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"i hope the world without wars\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"i hope the world without wars\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"I understand your desire for a world without wars. It's a noble goal that many people share. While a\"... 382 more characters,\n",
      "      tool_calls: [],\n",
      "      invalid_tool_calls: [],\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"I understand your desire for a world without wars. It's a noble goal that many people share. While a\"... 382 more characters,\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {},\n",
      "    tool_calls: [],\n",
      "    invalid_tool_calls: []\n",
      "  }\n",
      "] Human: i hope the world without wars\n",
      "AI: I understand your desire for a world without wars. It's a noble goal that many people share. While achieving a completely war-free world may be challenging, it is important for individuals to promote peace in their own lives and communities. Spreading empathy and understanding, and actively working towards peacefully resolving conflicts can all contribute to a more peaceful world. It starts with small actions, and by collectively working towards peace, we can make a difference. Bob expresses his hope for a world without wars, and the AI acknowledges this noble goal and the shared desire for peace. The AI emphasizes the importance of individuals promoting peace in their own lives and communities, highlighting actions such as spreading empathy, understanding, and actively working towards peacefully resolving conflicts. It emphasizes that while achieving a completely war-free world may be challenging, small actions taken collectively can make a difference and contribute to a more peaceful world.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"I understand your desire for a world without wars. It's a noble goal that many people share. While a\"\u001b[39m... 382 more characters"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatChain.invoke(\"i hope the world without wars\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
