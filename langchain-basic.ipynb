{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91798e70-32cf-469b-8aab-62890ede0451",
   "metadata": {},
   "source": [
    "# Basic Langchain configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0e8b49-02cb-48ed-808c-500254a5d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "// import env config\n",
    "\n",
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0a1e26-27ac-4cae-8c02-8735883926a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m13\u001b[39m, promptTokens: \u001b[33m11\u001b[39m, totalTokens: \u001b[33m24\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Initial langchain connection\n",
    "\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "\n",
    "await model.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce1537-8299-4ee4-b493-dd7399b19c73",
   "metadata": {},
   "source": [
    "## String Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe2b781-511b-4c51-9217-df7cda8b1bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Sure, here's a classic one for you:\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"Why don't scientists trust atoms?\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"Because they make up everyth\"\u001b[39m... 4 more characters"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = chatModel.pipe(outputPrase)\n",
    "\n",
    "await simpleChain.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56c850-6d4c-48ee-96e4-a6e395bfdfe3",
   "metadata": {},
   "source": [
    "In LCEL (LangChain Expression Language) we can use `.pipe()` to combine multiple `Runnable` to create a completed `Chain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439a33e1-ba35-4f34-9345-3bee1411ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Batch operation, response is list\n",
    "\n",
    "await simpleChain.batch([\n",
    "    [ new HumanMessage(\"Tell me a joke\") ],\n",
    "    [ new HumanMessage(\"Hi, Who are you?\") ],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ad4d2-620f-4c56-8d2a-210650c068b1",
   "metadata": {},
   "source": [
    "Here we introuced `stream`, bcz LLM's response is not completed at one time but consistantly.\n",
    "So we can use stream to improve the expirence of customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6445934e-be0b-41a5-b435-4686c0e54a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const stream = await simpleChain.stream([\n",
    "     new HumanMessage(\"Tell me a joke\"),\n",
    "    new HummanMessage(\"How to get inner peace ?\")\n",
    "])\n",
    "\n",
    "for await (const chunk of stream){\n",
    "    console.log(chunk)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799a5ff-1fcf-4dc0-b609-904cb1d21177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"replace\"\u001b[39m,\n",
      "      path: \u001b[32m\"\"\u001b[39m,\n",
      "      value: {\n",
      "        id: \u001b[32m\"814f867f-e981-4d54-8328-a21bc4ab7bc3\"\u001b[39m,\n",
      "        name: \u001b[32m\"RunnableSequence\"\u001b[39m,\n",
      "        type: \u001b[32m\"chain\"\u001b[39m,\n",
      "        streamed_output: [],\n",
      "        final_output: \u001b[90mundefined\u001b[39m,\n",
      "        logs: {}\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI\"\u001b[39m,\n",
      "      value: {\n",
      "        id: \u001b[32m\"53a99a71-b9d7-4150-9627-521ed4088742\"\u001b[39m,\n",
      "        name: \u001b[32m\"ChatOpenAI\"\u001b[39m,\n",
      "        type: \u001b[32m\"llm\"\u001b[39m,\n",
      "        tags: [ \u001b[32m\"seq:step:1\"\u001b[39m ],\n",
      "        metadata: {},\n",
      "        start_time: \u001b[32m\"2024-06-30T07:44:57.464Z\"\u001b[39m,\n",
      "        streamed_output: [],\n",
      "        streamed_output_str: [],\n",
      "        final_output: \u001b[90mundefined\u001b[39m,\n",
      "        end_time: \u001b[90mundefined\u001b[39m\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser\"\u001b[39m,\n",
      "      value: {\n",
      "        id: \u001b[32m\"ae1a9cf2-87a2-475a-a147-126dd984bc23\"\u001b[39m,\n",
      "        name: \u001b[32m\"StrOutputParser\"\u001b[39m,\n",
      "        type: \u001b[32m\"parser\"\u001b[39m,\n",
      "        tags: [ \u001b[32m\"seq:step:2\"\u001b[39m ],\n",
      "        metadata: {},\n",
      "        start_time: \u001b[32m\"2024-06-30T07:44:57.955Z\"\u001b[39m,\n",
      "        streamed_output: [],\n",
      "        streamed_output_str: [],\n",
      "        final_output: \u001b[90mundefined\u001b[39m,\n",
      "        end_time: \u001b[90mundefined\u001b[39m\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"Inner\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"Inner\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"Inner\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"Inner\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"Inner\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" peace\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" peace\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" peace\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" can\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" can\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" can\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" be\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" be\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" be\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" be\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" be\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" achieved\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" achieved\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" achieved\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" achieved\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" achieved\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" through\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" through\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" through\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" through\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" through\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" various\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" various\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" various\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" various\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" various\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" practices\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" practices\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" practices\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" practices\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" practices\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" perspectives\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" perspectives\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" perspectives\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" perspectives\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" perspectives\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Here\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Here\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Here\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Here\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Here\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" are\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" are\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" are\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" are\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" are\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" some\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" some\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" some\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" some\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" some\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" ways\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" ways\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" ways\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" ways\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" ways\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" cultivate\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" cultivate\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" cultivate\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" cultivate\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" cultivate\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" inner\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" inner\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" inner\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" inner\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" inner\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" peace\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" peace\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" peace\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"1\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"1\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"1\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"1\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"1\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Meditation\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Meditation\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Meditation\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Meditation\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Meditation\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Regular\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Regular\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Regular\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Regular\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Regular\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" meditation\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" meditation\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" meditation\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" meditation\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" meditation\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" practice\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" practice\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" practice\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" practice\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" practice\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" can\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" can\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" can\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" help\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" help\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" help\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" help\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" help\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" calm\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" calm\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" calm\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" calm\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" calm\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mind\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mind\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mind\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" reduce\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" reduce\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" reduce\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" reduce\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" reduce\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" stress\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" stress\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" stress\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" stress\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" stress\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" bring\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" bring\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" bring\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" bring\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" bring\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" about\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" about\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" about\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" about\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" about\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" a\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" a\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" a\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sense\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" sense\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sense\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" sense\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" sense\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" inner\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" inner\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" inner\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" inner\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" inner\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" peace\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" peace\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" peace\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Find\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Find\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Find\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Find\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Find\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" a\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" a\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" a\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peaceful\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" peaceful\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peaceful\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" peaceful\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" peaceful\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" space\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" space\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" space\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" space\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" space\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" dedicate\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" dedicate\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" dedicate\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" dedicate\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" dedicate\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" time\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" time\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" time\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" each\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" each\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" each\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" each\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" each\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" day\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" day\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" day\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" day\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" day\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sit\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" sit\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sit\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" sit\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" sit\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" quietly\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" quietly\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" quietly\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" quietly\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" quietly\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" focus\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" focus\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" focus\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" focus\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" focus\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" on\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" on\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" on\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" breath\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" breath\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" breath\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" breath\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" breath\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" let\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" let\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" let\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" let\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" let\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" go\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" go\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" go\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" negative\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" negative\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" negative\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" negative\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" negative\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" thoughts\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" thoughts\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" thoughts\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" thoughts\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" thoughts\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"2\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"2\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"2\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"2\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"2\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Mind\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Mind\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Mind\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Mind\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Mind\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"fulness\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"fulness\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"fulness\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"fulness\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"fulness\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Being\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Being\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Being\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Being\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Being\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" fully\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" fully\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" fully\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" fully\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" fully\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" present\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" present\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" present\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" present\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" present\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" in\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" in\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" in\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" moment\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" moment\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" moment\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" moment\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" moment\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" without\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" without\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" without\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" without\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" without\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" judgment\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" judgment\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" judgment\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" judgment\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" judgment\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" allows\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" allows\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" allows\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" allows\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" allows\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" you\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" you\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" you\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" let\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" let\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" let\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" let\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" let\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" go\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" go\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" go\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" worries\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" worries\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" worries\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" worries\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" worries\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" about\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" about\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" about\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" about\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" about\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" past\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" past\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" past\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" past\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" past\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" or\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" or\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" or\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" future\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" future\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" future\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" future\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" future\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Practice\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Practice\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Practice\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mindfulness\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mindfulness\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mindfulness\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mindfulness\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mindfulness\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" by\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" by\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" by\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" by\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" by\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" paying\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" paying\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" paying\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" paying\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" paying\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" attention\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" attention\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" attention\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" attention\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" attention\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" senses\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" senses\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" senses\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" senses\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" senses\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" breath\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" breath\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" breath\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" breath\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" breath\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" surroundings\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" surroundings\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" surroundings\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" surroundings\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" surroundings\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"3\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"3\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"3\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"3\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"3\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Gr\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Gr\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Gr\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Gr\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Gr\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"atitude\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"atitude\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"atitude\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"atitude\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"atitude\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Cult\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Cult\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Cult\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Cult\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Cult\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ivating\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ivating\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ivating\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ivating\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ivating\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" gratitude\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" gratitude\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" gratitude\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" gratitude\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" gratitude\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" for\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" for\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" for\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" for\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" for\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" things\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" things\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" things\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" things\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" things\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" you\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" you\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" you\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" have\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" have\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" have\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" have\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" have\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" in\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" in\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" in\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" life\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" life\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" life\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" life\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" life\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" can\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" can\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" can\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" shift\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" shift\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" shift\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" shift\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" shift\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" focus\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" focus\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" focus\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" focus\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" focus\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" from\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" from\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" from\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" from\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" from\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" what\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" what\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" what\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"'s\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"'s\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"'s\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"'s\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"'s\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" lacking\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" lacking\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" lacking\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" lacking\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" lacking\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" what\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" what\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" what\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"'s\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"'s\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"'s\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"'s\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"'s\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" abundant\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" abundant\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" abundant\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" abundant\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" abundant\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Take\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Take\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Take\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Take\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Take\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" time\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" time\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" time\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" each\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" each\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" each\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" each\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" each\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" day\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" day\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" day\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" day\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" day\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" reflect\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" reflect\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" reflect\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" reflect\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" reflect\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" on\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" on\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" on\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" appreciate\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" appreciate\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" appreciate\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" appreciate\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" appreciate\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" positive\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" positive\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" positive\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" positive\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" positive\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" aspects\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" aspects\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" aspects\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" aspects\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" aspects\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" life\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" life\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" life\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" life\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" life\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"4\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"4\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"4\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"4\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"4\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Let\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Let\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Let\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Let\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Let\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ting\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ting\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ting\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ting\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ting\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" go\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" go\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" go\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" attachments\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" attachments\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" attachments\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" attachments\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" attachments\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Attach\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Attach\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Attach\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Attach\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Attach\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ments\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ments\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ments\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ments\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ments\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" outcomes\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" outcomes\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" outcomes\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" outcomes\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" outcomes\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" possessions\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" possessions\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" possessions\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" possessions\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" possessions\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" or\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" or\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" or\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" relationships\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" relationships\"\u001b[39m }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" relationships\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" relationships\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" relationships\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" can\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" can\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" can\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" bring\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" bring\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" bring\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" bring\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" bring\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" about\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" about\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" about\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" about\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" about\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" stress\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" stress\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" stress\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" stress\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" stress\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" anxiety\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" anxiety\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" anxiety\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" anxiety\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" anxiety\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Practice\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Practice\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Practice\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" letting\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" letting\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" letting\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" letting\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" letting\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" go\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" go\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" go\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" go\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" attachment\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" attachment\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" attachment\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" attachment\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" attachment\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" embracing\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" embracing\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" embracing\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" embracing\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" embracing\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" imper\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" imper\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" imper\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" imper\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" imper\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"man\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"man\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"man\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"man\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"man\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ence\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ence\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ence\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ence\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ence\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" life\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" life\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" life\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" life\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" life\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Focus\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Focus\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Focus\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Focus\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Focus\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" on\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" on\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" on\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" what\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" what\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" what\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" you\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" you\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" you\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" can\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" can\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" can\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" control\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" control\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" control\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" control\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" control\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" have\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" have\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" have\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" have\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" have\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" acceptance\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" acceptance\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" acceptance\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" acceptance\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" acceptance\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" for\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" for\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" for\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" for\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" for\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" what\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" what\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" what\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" what\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" you\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" you\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" you\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" cannot\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" cannot\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" cannot\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" cannot\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" cannot\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"5\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"5\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"5\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"5\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"5\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Self\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Self\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Self\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Self\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Self\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"-\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"-\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"-\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"compass\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"compass\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"compass\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"compass\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"compass\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ion\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ion\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ion\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ion\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ion\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Treat\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Treat\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Treat\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Treat\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Treat\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" yourself\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" yourself\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" yourself\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" with\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" with\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" with\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" kindness\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" kindness\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" kindness\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" kindness\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" kindness\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" understanding\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" understanding\"\u001b[39m }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" understanding\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" understanding\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" understanding\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" forgiveness\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" forgiveness\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" forgiveness\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" forgiveness\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" forgiveness\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Practice\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Practice\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Practice\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" self\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" self\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" self\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" self\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" self\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"-\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"-\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"-\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"compass\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"compass\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"compass\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"compass\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"compass\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ion\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ion\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ion\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ion\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ion\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" by\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" by\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" by\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" by\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" by\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" being\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" being\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" being\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" being\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" being\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" gentle\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" gentle\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" gentle\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" gentle\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" gentle\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" with\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" with\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" with\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" yourself\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" yourself\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" yourself\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" acknowledging\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" acknowledging\"\u001b[39m }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" acknowledging\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" acknowledging\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" acknowledging\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" strengths\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" strengths\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" strengths\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" strengths\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" strengths\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" learning\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" learning\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" learning\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" learning\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" learning\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" from\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" from\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" from\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" from\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" from\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mistakes\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mistakes\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mistakes\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mistakes\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mistakes\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"6\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"6\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"6\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"6\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"6\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Physical\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Physical\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Physical\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Physical\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Physical\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" well\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" well\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" well\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" well\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" well\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-being\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"-being\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-being\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"-being\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"-being\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Take\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Take\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Take\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Take\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Take\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" care\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" care\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" care\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" care\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" care\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" physical\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" physical\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" physical\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" physical\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" physical\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" health\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" health\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" health\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" health\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" health\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" as\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" as\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" as\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" as\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" as\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" it\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" it\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" it\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" it\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" it\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" can\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" can\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" can\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" greatly\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" greatly\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" greatly\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" greatly\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" greatly\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" impact\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" impact\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" impact\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" impact\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" impact\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mental\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mental\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mental\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mental\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mental\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" emotional\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" emotional\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" emotional\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" emotional\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" emotional\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" well\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" well\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" well\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" well\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" well\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-being\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"-being\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"-being\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"-being\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"-being\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Eng\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Eng\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Eng\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Eng\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Eng\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"age\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"age\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"age\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"age\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"age\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" in\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" in\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" in\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" regular\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" regular\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" regular\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" regular\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" regular\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" exercise\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" exercise\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" exercise\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" exercise\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" exercise\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" maintain\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" maintain\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" maintain\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" maintain\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" maintain\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" a\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" a\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" a\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" balanced\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" balanced\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" balanced\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" balanced\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" balanced\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" diet\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" diet\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" diet\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" diet\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" diet\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" get\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" get\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" get\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" get\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" get\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sufficient\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" sufficient\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sufficient\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" sufficient\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" sufficient\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sleep\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" sleep\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sleep\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" sleep\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" sleep\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"7\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"7\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"7\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"7\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"7\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Surround\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Surround\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Surround\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Surround\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Surround\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" yourself\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" yourself\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" yourself\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" with\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" with\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" with\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" positive\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" positive\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" positive\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" positive\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" positive\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" influences\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" influences\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" influences\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" influences\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" influences\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Spend\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Spend\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Spend\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Spend\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Spend\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" time\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" time\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" time\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" with\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" with\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" with\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" people\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" people\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" people\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" people\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" people\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" who\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" who\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" who\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" who\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" who\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" uplift\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" uplift\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" uplift\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" uplift\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" uplift\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" support\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" support\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" support\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" support\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" support\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" you\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" you\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" you\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" you\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Avoid\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Avoid\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Avoid\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Avoid\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Avoid\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" negative\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" negative\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" negative\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" negative\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" negative\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" or\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" or\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" or\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" toxic\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" toxic\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" toxic\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" toxic\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" toxic\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" environments\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" environments\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" environments\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" environments\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" environments\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" relationships\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" relationships\"\u001b[39m }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" relationships\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" relationships\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" relationships\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" that\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" that\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" that\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" that\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" that\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" drain\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" drain\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" drain\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" drain\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" drain\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" energy\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" energy\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" energy\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" energy\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" energy\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" peace\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" peace\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" peace\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mind\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mind\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mind\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"8\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"8\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"8\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"8\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"8\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Practice\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Practice\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Practice\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" forgiveness\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" forgiveness\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" forgiveness\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" forgiveness\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" forgiveness\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Holding\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Holding\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Holding\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Holding\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Holding\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" onto\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" onto\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" onto\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" onto\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" onto\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" gr\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" gr\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" gr\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" gr\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" gr\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ud\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ud\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ud\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ud\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ud\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ges\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ges\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ges\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ges\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ges\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" or\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" or\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" or\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" resentment\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" resentment\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" resentment\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" resentment\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" resentment\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" can\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" can\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" can\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" can\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" weigh\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" weigh\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" weigh\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" weigh\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" weigh\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" heavily\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" heavily\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" heavily\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" heavily\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" heavily\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" on\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" on\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" on\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" on\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" your\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" your\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mind\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mind\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mind\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" heart\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" heart\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" heart\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" heart\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" heart\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Practice\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Practice\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Practice\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Practice\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" forgiveness\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" forgiveness\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" forgiveness\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" forgiveness\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" forgiveness\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" both\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" both\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" both\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" both\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" both\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" for\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" for\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" for\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" for\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" for\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" others\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" others\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" others\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" others\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" others\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" yourself\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" yourself\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" yourself\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" yourself\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" to\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" to\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" to\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" to\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" release\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" release\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" release\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" release\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" release\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" negative\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" negative\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" negative\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" negative\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" negative\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" emotions\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" emotions\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" emotions\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" emotions\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" emotions\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" achieve\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" achieve\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" achieve\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" achieve\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" achieve\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" peace\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" peace\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" peace\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" peace\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"9\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"9\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"9\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"9\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"9\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Connect\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Connect\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Connect\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Connect\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Connect\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" with\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" with\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" with\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" with\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" nature\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" nature\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" nature\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" nature\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" nature\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\":\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\":\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\":\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\":\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Spend\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Spend\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Spend\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Spend\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Spend\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" time\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" time\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" time\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" time\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" in\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" in\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" in\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" nature\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" nature\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" nature\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" nature\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" nature\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" whether\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" whether\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" whether\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" whether\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" whether\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" it\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" it\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" it\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" it\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" it\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"'s\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"'s\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"'s\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"'s\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"'s\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" walking\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" walking\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" walking\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" walking\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" walking\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" in\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" in\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" in\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" a\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" a\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" a\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" park\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" park\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" park\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" park\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" park\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sitting\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" sitting\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sitting\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" sitting\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" sitting\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" by\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" by\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" by\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" by\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" by\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" beach\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" beach\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" beach\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" beach\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" beach\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\",\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\",\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\",\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\",\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" or\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" or\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" or\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" or\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" hiking\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" hiking\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" hiking\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" hiking\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" hiking\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" in\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" in\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" in\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" in\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mountains\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mountains\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mountains\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mountains\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mountains\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Nature\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Nature\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Nature\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Nature\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Nature\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" has\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" has\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" has\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" has\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" has\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" a\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" a\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" a\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" way\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" way\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" way\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" way\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" way\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" calming\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" calming\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" calming\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" calming\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" calming\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" the\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" the\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" the\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" the\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" mind\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" mind\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" mind\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" mind\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" and\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" and\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" and\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" and\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" inst\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" inst\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" inst\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" inst\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" inst\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"illing\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"illing\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"illing\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"illing\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"illing\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" a\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" a\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" a\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" a\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sense\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" sense\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" sense\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" sense\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" sense\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" of\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" of\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" of\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" of\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" tranqu\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" tranqu\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" tranqu\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" tranqu\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" tranqu\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ility\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ility\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ility\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ility\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ility\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\\n\\n\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\\n\\n\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\\n\\n\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"10\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"10\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"10\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"10\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"10\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\".\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\".\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\".\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\".\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Simpl\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" Simpl\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" Simpl\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\" Simpl\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\" Simpl\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ify\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\"ify\"\u001b[39m } ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output_str/-\"\u001b[39m,\n",
      "      value: \u001b[32m\"ify\"\u001b[39m\n",
      "    },\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/ChatOpenAI/streamed_output/-\"\u001b[39m,\n",
      "      value: ChatGenerationChunk {\n",
      "        text: \u001b[32m\"ify\"\u001b[39m,\n",
      "        generationInfo: { prompt: \u001b[33m0\u001b[39m, completion: \u001b[33m0\u001b[39m, finish_reason: \u001b[1mnull\u001b[22m },\n",
      "        message: AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[32m\"ify\"\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [\n",
      "    {\n",
      "      op: \u001b[32m\"add\"\u001b[39m,\n",
      "      path: \u001b[32m\"/logs/StrOutputParser/streamed_output/-\"\u001b[39m,\n",
      "      value: \u001b[32m\" your\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "RunLogPatch {\n",
      "  ops: [ { op: \u001b[32m\"add\"\u001b[39m, path: \u001b[32m\"/streamed_output/-\"\u001b[39m, value: \u001b[32m\" your\"\u001b[39m } ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// stream log: return completed object at each time chunks are replied.\n",
    "\n",
    "const stream = await simpleChain.streamLog([\n",
    "    new HumanMessage(\"How to get inner peace ?\")\n",
    "])\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    console.log(chunk)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f75bc-79a1-4a0d-bfb6-2b906a1892eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
