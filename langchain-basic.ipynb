{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91798e70-32cf-469b-8aab-62890ede0451",
   "metadata": {},
   "source": [
    "# Basic Langchain configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0e8b49-02cb-48ed-808c-500254a5d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "// import env config\n",
    "\n",
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0a1e26-27ac-4cae-8c02-8735883926a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Sure, here's a classic one for you:\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Why don't scientists trust atoms?\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Because they make up everyth\"\u001b[39m... 4 more characters,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Sure, here's a classic one for you:\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Why don't scientists trust atoms?\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Because they make up everyth\"\u001b[39m... 4 more characters,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m23\u001b[39m, promptTokens: \u001b[33m11\u001b[39m, totalTokens: \u001b[33m34\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Initial langchain connection\n",
    "\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "\n",
    "await model.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe2b781-511b-4c51-9217-df7cda8b1bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Sure, here's a classic one for you:\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"Why don't scientists trust atoms?\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"Because they make up everyth\"\u001b[39m... 4 more characters"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const outputPrase = new StringOutputParser();\n",
    "\n",
    "const simpleChain = chatModel.pipe(outputPrase)\n",
    "\n",
    "await simpleChain.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439a33e1-ba35-4f34-9345-3bee1411ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "await simpleChain.batch([\n",
    "    [ new HumanMessage(\"Tell me a joke\") ],\n",
    "    [ new HumanMessage(\"Hi, Who are you?\") ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6445934e-be0b-41a5-b435-4686c0e54a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " don\n",
      "'t\n",
      " scientists\n",
      " trust\n",
      " atoms\n",
      "?\n",
      " \n",
      "\n",
      "\n",
      "Because\n",
      " they\n",
      " make\n",
      " up\n",
      " everything\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "const stream = await simpleChain.stream([\n",
    "     new HumanMessage(\"Tell me a joke\")\n",
    "])\n",
    "\n",
    "for await (const chunk of stream){\n",
    "    console.log(chunk)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799a5ff-1fcf-4dc0-b609-904cb1d21177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
